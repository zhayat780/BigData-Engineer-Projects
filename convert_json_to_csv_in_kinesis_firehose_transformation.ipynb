{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Untitled65.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyOdiWgfWBWm9pbX35jH41xX"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# **Lambda Code to transform Json to CSV in Kinesis Firehose**"
      ],
      "metadata": {
        "id": "1Kw7Vb5ZnA-N"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import json\n",
        "import boto3\n",
        "import base64\n",
        "\n",
        "output = []\n",
        "\n",
        "def lambda_handler(event, context):\n",
        "    print(event)\n",
        "    for record in event['records']:\n",
        "        payload = json.loads(base64.b64decode(record['data']).decode('utf-8'))\n",
        "        print('payload:', payload)\n",
        "        \n",
        "        output_payload=\"\"\n",
        "        for i in payload:\n",
        "            output_payload=output_payload+str(payload[i])\n",
        "            output_payload=output_payload+\",\"\n",
        "            \t\n",
        "        output_payload_clean=output_payload[:-1]+ \"\\n\"\n",
        "        \n",
        "        output_payload_postprocessed = base64.b64encode(output_payload_clean.encode('utf-8'))\n",
        "        \n",
        "        output_record = {\n",
        "            'recordId': record['recordId'],\n",
        "            'result': 'Ok',\n",
        "            'data': output_payload_postprocessed\n",
        "        }\n",
        "        output.append(output_record)\n",
        "\n",
        "    print('Processed {} records.'.format(len(event['records'])))\n",
        "    \n",
        "    return {'records': output}"
      ],
      "metadata": {
        "id": "0RRqUqubnG7E"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Data Producer**"
      ],
      "metadata": {
        "id": "VrdSKjH0nJmC"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9dyje2dbVYK1"
      },
      "outputs": [],
      "source": [
        "!pip install boto3"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "aws_access_key=''\n",
        "aws_secret_key=''\n",
        "region=''"
      ],
      "metadata": {
        "id": "QFTZ6VTwVpIv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import json\n",
        "import datetime\n",
        "import random\n",
        "import boto3\n",
        "session=boto3.Session(aws_access_key_id=aws_access_key,\n",
        "                      aws_secret_access_key=aws_secret_key, region_name=region)\n",
        "\n",
        "client = session.client('kinesis')\n",
        "\n",
        "kinesis_stream=\"{}\"\n",
        "\n",
        "\n",
        "def getData(iotName, lowVal, highVal):\n",
        "   data = {}\n",
        "   data[\"iotName\"] = iotName\n",
        "   data[\"iotValue\"] = random.randint(lowVal, highVal) \n",
        "   return data\n",
        "\n",
        "temp=0;\n",
        "\n",
        "while temp<100:\n",
        "   rnd = random.random()\n",
        "   if (rnd < 0.01):\n",
        "      data = json.dumps(getData(\"DemoSensor\", 100, 120))  \n",
        "      client.put_record(StreamName=kinesis_stream, Data=data, PartitionKey=\"1\")\n",
        "      print('*************************** anomaly *********************** ' + data)\n",
        "   else:\n",
        "      data = json.dumps(getData(\"DemoSensor\", 10, 20))  \n",
        "      client.put_record(StreamName=kinesis_stream, Data=data, PartitionKey=\"1\")\n",
        "      print(data)\n",
        "   temp=temp+1"
      ],
      "metadata": {
        "id": "SpUDTvlYVY7h"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Read the data from s3 **"
      ],
      "metadata": {
        "id": "WCVE7sYunOFe"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!apt-get update\n",
        "!apt-get install openjdk-8-jdk-headless -qq > /dev/null\n",
        "!wget -q htt  https://archive.apache.org/dist/spark/spark-2.3.1/spark-2.3.1-bin-hadoop2.7.tgz\n",
        "!tar xf spark-2.3.1-bin-hadoop2.7.tgz\n",
        "!pip install -q findspark\n",
        "\n",
        "import os\n",
        "os.environ[\"JAVA_HOME\"] = \"/usr/lib/jvm/java-8-openjdk-amd64\"\n",
        "os.environ[\"SPARK_HOME\"] = \"/content/spark-2.3.1-bin-hadoop2.7\"\n",
        "\n",
        "import findspark\n",
        "findspark.init()\n",
        "from pyspark.sql import SparkSession"
      ],
      "metadata": {
        "id": "tdKyXDNiV3DA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "spark = SparkSession \\\n",
        ".builder \\\n",
        ".config(\"spark.jars.packages\", \"org.apache.hadoop:hadoop-aws:2.7.3,com.amazonaws:aws-java-sdk:1.7.4\") \\\n",
        ".config(\"fs.s3a.impl\",\"org.apache.hadoop.fs.s3a.S3AFileSystem\") \\\n",
        ".config(\"fs.s3a.access.key\",aws_access_key ) \\\n",
        ".config(\"fs.s3a.secret.key\", aws_secret_key) \\\n",
        ".getOrCreate()"
      ],
      "metadata": {
        "id": "cp2Ty6yNV5S5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "sdf = spark.read.option(\"header\", \"false\").option(\"inferschema\", \"true\").csv(\"{}\")"
      ],
      "metadata": {
        "id": "Ox6vGqSZWAXS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "sdf.show()"
      ],
      "metadata": {
        "id": "XKMrhUR7ei8-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "sdf.count()"
      ],
      "metadata": {
        "id": "9BP1mgphen03"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}